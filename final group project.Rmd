---
title: "Final project: Ask a Manager Analysis"
subtitle: "Study Group 6"
output: html_document
---

```{r setup, include=FALSE}
library(googlesheets4)
library(tidyverse)
library(janitor) 
library(skimr)
library(countrycode) # to clean up country names
library(broom)
library(car)
library(ggfortify)

```


```{r }

# use googlesheets4 to get data

url <- "https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/edit?resourcekey#gid=1625408792"
googlesheets4::gs4_auth() # google sheets authorisation

# load "Ask a A Manager 2021 Survey" googlesheet
# https://www.askamanager.org/
ask_a_manager_2021 <- googlesheets4::read_sheet(url) %>% 
  janitor::clean_names()

# if googlesheets is now working, read local copy
# ask_a_manager_2021 <- read_csv(here::here("data", "ask_a_manager_2021.csv"))

```

## R Markdown

```{r cars}
clean_data1 <- ask_a_manager_2021%>%
  drop_na(industry)%>%
select(-"additional_context_on_job_title") %>% 
select(-"additional_context_on_income")%>%
select(-"currency_other")%>%
select(-"state")%>%
select(-"city")

clean_data1$other_monetary_comp[is.na(clean_data1$other_monetary_comp)]= 0 
clean_data2 <- clean_data1 %>% 
  mutate(other_monetary_comp = as.numeric(replace(other_monetary_comp, which(other_monetary_comp == "NULL"), 0)))
clean_data3 <- clean_data2 %>% 
  mutate(total_salary = other_monetary_comp + annual_salary)

# exchange different currency to new column, named USD_exchange
## write a function to convert currency 
 currencyCon <- function(x,from = "USD", to = "EUR"){
   values<-c(1.00,0.92,0.81,1.27)
   names(values)<-c("USD","EUR","GBP","CAD")
   values[to]/(values[from]/x)
 }

## apply the function and create a new column
clean_data4 <- clean_data3 %>% 
  mutate(USD_exchange = currencyCon(clean_data3$total_salary, clean_data3$currency, "USD"))

clean_data5 <- clean_data4 %>% 
  mutate(country=countryname(country,'iso3c'))%>%
  drop_na(country) 


```


```{r pressure, echo=FALSE}
clean_data <- clean_data5 %>% 
  filter(gender!="Non-binary")%>%
 filter(gender!="Other or prefer not to answer")%>%
  filter(gender!="Prefer not to answer")
  
mean_clean <- clean_data %>% 
  group_by(gender, industry)%>%
  summarise(mean1=mean(USD_exchange))

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
```{r ppp data}
ppp_data1 <- read_csv(here::here("data","pppdata.csv"))

ppp_data2 <- ppp_data1 %>% 
  filter(TIME == "2020") 

ppp_data3<-ppp_data2[!(ppp_data2$LOCATION=="EU27_2020" | ppp_data2$LOCATION=="EA19"),]
 
```

```{r left join}
ppp_data4 <- ppp_data3 %>% select(LOCATION, Value)
merge_data <- left_join(clean_data, ppp_data4, by = c('country' = 'LOCATION'))

ppp_data<- merge_data %>% 
  mutate(ppp_salary = total_salary / Value) %>% 
filter(!is.na(Value))

ppp_data<- merge_data %>% 
  mutate(ppp_salary = total_salary / Value) %>% 
  filter(!is.na(Value))

```


```{r}
library(stringr)
# 
# filter(ppp_data, str_detect(industry, "Pharmaa*"))
# ppp_data %>% 
#   filter(str_detect(industry,"profa*")) 

# str_view(ppp_data$industry,"^Edua*")

ppp_data5 <- ppp_data %>%
  mutate(
    industry = case_when(
     str_detect(ppp_data$industry, "^Acaa*") ~ "Academia",
     str_detect(ppp_data$industry, "pharmaa*") ~ "Pharmaceuticals",
     str_detect(ppp_data$industry, "Pharmaa*") ~ "Pharmaceuticals",
     str_detect(ppp_data$industry, "^Accounta*") ~ "Accounting, Banking & Finance",
    str_detect(ppp_data$industry, "profa*") ~ "Nonprofits",
    TRUE ~ industry
    )
  )

ppp_data_industry <-  ppp_data5 %>% 
  count(industry,sort=TRUE) %>% 
  mutate(percent=100* n/sum(n)) %>% 
  filter(percent>1)

ppp_industry <- ppp_data_industry$industry

ppp_data_clean <- ppp_data %>% 
  filter(industry %in% ppp_industry)

```


# Plot

To begin with our analysis, we will look at the number of responses by industry and focus on the ones with the most responses to ensure that the dataset is significant enough to make relevant conclusions.   

```{r introductory ppp analysis}

ppp_data_clean %>%
  drop_na(industry) %>%
  group_by(industry) %>%
  summarise(Freq = n()) %>%
  ggplot(aes(fct_reorder(industry, Freq),Freq)) +
  geom_bar(stat = "identity", fill = "blue") +
  geom_text(aes(label = Freq), position = position_dodge(width = 1), hjust = -0.2, size = 1.5) +
  coord_flip() +
  xlab("Industry") +
  ylab("Number of responses") +
  ggtitle("Responses by Industry") +
  theme_bw()

# ggplot(ppp_data_clean, aes(x=ppp_salary))+
# geom_point()
```

```{r}
ppp_data_clean %>% 
  group_by(industry) %>% 
  ggplot(aes(x=ppp_salary,y=industry,color=gender))+
  # facet_wrap(gender~.)+
  geom_point(alpha=0.2)+
  scale_color_manual(values = c("Man" = "blue", "Woman" = "red"))+
  labs(title = "Purchasing Power Parity Salary by Industry",
       subtitle = "Split by Gender",
       y= "Industry",
       x= "Purchasing Power Parity related Salary",
       colour= "Gender")+
  xlim(0, 500000) 

```
We look at the purchasing power parity salary to have a ground for comparison when looking at all countries, as a $1 in one country is not worth as much in another. 
The industry with the most respondents, Computing/Tech, seems to be heavily male-dominated, especially when looking at the higher salaries. 
```{r average gender gap}

# Average gender gap in the US by industry

plot1<-ppp_data_clean%>%
  select(gender,industry,ppp_salary,country)%>%
 filter(gender!="Non-binary")%>%
 filter(gender!="Other or prefer not to answer")%>%
 filter(gender!="Prefer not to answer")%>%
 filter(country =="USA")

plot2<-plot1%>%  
 group_by(industry,gender)%>%
 summarise(mean=mean(ppp_salary))

plot1man<-plot2%>% 
  filter(gender =="Man")

plot2woman<-plot2%>%
  filter(gender =="Woman")

plot<-left_join(plot1man,plot2woman,by = "industry")%>%
  mutate(gap=mean.x-mean.y)

plot%>%
  ggplot(aes(x=gap,y=reorder(industry, gap),group=1,fill = gap))+
  geom_bar(stat='identity')+
  labs(title = "Average gender gap in the US by industry",
       subtitle = "Woman / Man",
       x="$",
       y= "industry")+
  theme_bw()
  
```

```{r}
# Average Salary in the US by industry

plot3<-plot1%>%
  select(industry,ppp_salary)%>%
group_by(industry)%>%
summarise(mean1=mean(ppp_salary))
  
  plot3%>%
  ggplot(aes(x=mean1,y=reorder(industry, mean1),group=1,fill = mean1))+
  geom_histogram(stat='identity')+
  labs(title = "Average Salary in the US by industry",
       x="$",
       y= "industry")+
   theme(axis.text=element_text(size=8),
        axis.title=element_text(size=10),
        axis.text.x = element_blank()) +
    theme_bw()
  
```

```{r}
# Average Salary in the US by educational level

plot4<-ppp_data_clean%>%
  drop_na(highest_level_of_education_completed)%>%
  drop_na(USD_exchange)%>%
  select(highest_level_of_education_completed,USD_exchange,country)%>%
  filter(country=="USA")%>%
  group_by(highest_level_of_education_completed)%>%
  summarise(mean2=mean(USD_exchange))

plot4 %>%
  ggplot(aes(x=mean2,y=reorder(highest_level_of_education_completed, mean2),group=1,fill=mean2))+
  geom_bar(stat='identity')+
  labs(title = "Average Salary in the US by educational level",
       x="$",
       y= "educational level")+
   theme(axis.text=element_text(size=8),
        axis.title=element_text(size=10))+
  theme_bw()


```


```{r}

#Average ppp_salary worldwide by industry
library(scales)

plot5<-ppp_data_clean%>%
  select(industry,country,ppp_salary)%>%
  group_by(country,industry)%>% 
  summarise(mean3=mean(ppp_salary))

big_country <- ppp_data_clean %>% 
  count(country, sort = TRUE) %>% 
  mutate(percent = 100*n/sum(n)) %>% 
  filter(percent >0.05)

big_country_list <- big_country$country
plot6 <- plot5 %>% 
  filter(country %in% big_country_list)



# create list of gdp per capita of each country
   values<-c(57447,53265,47607,48137,84987,49548,62709,32026,52131,43959,42915,2338,81315,45958,43597,55606,46278,56763,66678,6441)
   names<-c("AUS","AUT","BEL","CAN","CHE","DEU","DNK","ESP","FIN","FRA","GBR","IND","IRL","ISR","JPN","NLD","NZL","SWE","USA","ZAF")
   
gdp_list <- do.call(rbind, Map(data.frame, A = values, B = names))
colnames(gdp_list) <- c("gdp", "country")

# merge gdp list with origional data
plot7 <- left_join(plot6, gdp_list, by = "country")

# plot with both scatter point and smooth line, x axis is ordered by GDP per capita
plot7%>%
    ggplot(aes(x=reorder(country, gdp),y=mean3,group=1,color=industry))+
  geom_point()+
  geom_smooth(method=lm)+
  scale_y_continuous(labels = dollar)+
  labs(title = "Average ppp_salary distribution by industry and country",
       x="Country",
       y= "Average ppp_salary")+
   theme(axis.text=element_text(size=8),
        axis.title=element_text(size=10))+
  theme_bw()

# plot with only smooth line, x axis is ordered by GDP per capita
plot7%>%
    ggplot(aes(x=reorder(country, gdp),y=mean3,group=1,color=industry))+
  #geom_point()+
  geom_smooth(method = lm)+
  labs(title = "Average ppp_salary distribution by industry and country",
       x="Country",
       y= "Average ppp_salary")+
   theme(axis.text=element_text(size=8),
        axis.title=element_text(size=10))+
  theme_bw()


```


```{r}
ppp_data_clean %>%
  ggplot(aes(x=ppp_salary,y=industry,color=gender))+
  geom_point()+
  scale_color_manual(values = c("Man" = "blue", "Woman" = "red"))+
  xlim(0, 500000)+
  theme_bw()+
  labs(title = "Average ppp_salary distribution by gender and industry",
       x="ppp_salary",
       y= "Industry")


```

We will now clean our race column. If we run a the `unique` function in r on the race column we see that there are 44 different categories. We will separate the race into white, non white and unanswered.

We then take out the Not Answered values as can be seen in the code below. 

```{r}

ppp_data_final_clean <- ppp_data_clean %>%
  drop_na(race, USD_exchange, highest_level_of_education_completed) %>% 
  mutate(
    race_filtered = case_when(
    str_detect(race, "^Whitea*") ~ "White",
    str_detect(race, "Another option not listed here or prefer not to answer*") ~ "Not Answered",
    TRUE ~ "Non White"
    )
  ) %>% 
  filter(!race_filtered=="Not Answered")



```

# Regression

For our regression analysis, we are aiming to predict the total salary (annual salary and  other monnetary compensation) for the USA,  as this country has the highest number of observations and we are attempting to achieve a higher model accuracy. 
```{r Regression}
ppp_reg <- ppp_data_final_clean %>% 
  filter(country== "USA")

model1  <- lm(total_salary ~ industry, data=ppp_reg)
mosaic::msummary(model1)
confint(model1)

model2  <- lm(total_salary ~ industry + years_of_experience_in_field , data=ppp_reg)
mosaic::msummary(model2)
confint(model2)

model3 <- lm(total_salary ~ industry + years_of_experience_in_field + highest_level_of_education_completed, data=ppp_reg)
mosaic::msummary(model3)
confint(model3)

model4 <- lm(total_salary ~ industry + years_of_experience_in_field + highest_level_of_education_completed + gender, data=ppp_reg)
mosaic::msummary(model4)
confint(model4)

model5 <- lm(total_salary ~ industry + years_of_experience_in_field + highest_level_of_education_completed + gender+ overall_years_of_professional_experience, data=ppp_reg)
mosaic::msummary(model5)
confint(model5)

model6 <- lm(total_salary ~ industry + years_of_experience_in_field + highest_level_of_education_completed + gender+ overall_years_of_professional_experience + race_filtered , data=ppp_reg)
mosaic::msummary(model6)
confint(model6)


huxtable::huxreg(model1, model2, model3, model4, model5, model6)
```
To begin with, we run a linear regression model while only including the variable industry which we have cleaned to only include the top 20 industries in our dataframe (which all account for more than 1% of observations in our dataframe). Upon running the regression, we achieve an R squared of 10.33% which means that the predictor variable industry explains 10.33% of our dependent/response variable "total_salary". We can also look at the residual standard error to evaluate how well the linear regression model fits the data. This measure  shows the average amount that the real values of total salary differ from the predictions our regression line provides. Our residual standard error  of 88340 indicates that on average the actual total salary of a person in the US deviates from our regression line by approximately 88340  dollars. While looking at our regression table, we can distinguish which variables are statistically significant by looking at the p-value and the indication of stars after the variables. Furthermore, the t-value shows how many standard deviations out coefficient estimate is situated compared to 0. If our t-stat is more than 2, it is a strong indication that we can reject the null hypothesis (there is no salary difference between different industries) and indicate a relationship  between the two variables. As  we can see, our model indicates that most industries are statistically significant in terms of  our model, showcased by for example the variable 'industryComputing or Tech'  with a p-value smaller than 0.01, indicating that someone in the Computing or Tech industry would earn on average 47767.5 dollars more than someone in the 'control' industry which is Accounting, Banking & Finance while someone in the Art & Design  industry would earn on average 17613.1 dollars less than someone in Accounting, Banking & Finance. However, for the Engineering or Manufacturing industry we observe a t-value of less than 2 and a large p-value of 0.84, indicating no statistical significance that there is a difference between the total salary for a person in Accounting, Banking & Finance and Engineering or Manufacturing. The intercept of 108566.2 dollars indicates the total  salary with no industry. Furthermore, we can analyse the 95% confidence interval for each industry to see where 95% of the predicted total salary observations lie in terms of the baseline. For example, for the Computing or Tech industry 95% of total salaries  differ from the baseline industry Accounting, Banking & Finance's total salary in the range of 42126.9402 to 53408.067.
All in all,  our simplistic model 1 is not very good at predicting total salary, meaning that we should add other variables to increase accuracy. Consequently, the R squared will increase while running a multiple regression, as more variables are included in the  model. The adjusted R squared solves this problem by adjusting for the number of considered variables.

Our models 2-5 consecutively add other variables to the model: years of experience in field, highest level of education completed, gender and overall years of professional experience. With each addition the R squared measure increases, indicating that our model is explaining more of the dependent variable total salary. While adding new variables, our model follows the same logic as described above. For years of experience in field all of the variables are statistically significant for our model while compared the baseline of 1 year or less. The salary increase goes up with the amount of years in industry. In model 3, highest level of education completed has the baseline of College education with all other variables being statistically significant, and  each degree at a lower level than college earning less and each degree at a higher level earning more than a college educated person average, while controlling for the other variable categories in our model. Model 4 has male as a baseline with woman being statistically significant, indicating that women earn on average 26779 dollars less than men while controlling for other variables. Model 5 also incorporates overall years of professional experience, for which only two variables are statistically significant, meaning that the category is not very good for explaining the differences in total salary. This is also supported by a comparison of th R squared measures for model 4 and 5 (seen in the table comparison of regression model results), as the R squared only increases from 19% to 19.1%. 

Finally, we derive our final model 6 which incorporates years of experience in field, highest level of education completed, gender and overall years of professional experience and gender. This model achieves an R squared of 19.3%, showing that our model variables explain 19.3% of the dependent variable total salary. Race is deemed statistically significant at the 0.01 p-value, showing that white people on earn on average -12532.0 dollars less than people we have grouped as non-white. It is important to note that in our data cleaning process, race originally had 44 different input variables and grouping these to only 3 (white, non-white and prefer not to say) influences our prediction results. All in all, the standard error is 83870 dollars, showing that while our final linear regression model fits the data better than our initial model 1, on average the actual total salary still deviates from our regression line by a substantial amount. Hence, the R squared and residual standard errors indicate a limited explanatory power of our model and that it should be significantly improved by adding better explanatory variables. We hypothesise that looking at the state variable in the US would increase model accuracy, as people in wealthier states such as Los Angeles or New York earn on average more than in other states. The comparison of our 6 models and their number of observations, R squared values and statistically significant variables is given as the last table in our analysis.